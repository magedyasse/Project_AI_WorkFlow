{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecb73aa",
   "metadata": {},
   "source": [
    "# Monthly Revenue Forecasting: Data Exploration & Requirements\n",
    "\n",
    "**Business Objective:** Accurate monthly revenue forecasting for May (using data up to April)\n",
    "\n",
    "**ML Task:** Time-aware supervised regression with forecasting constraints\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Objectives\n",
    "1. Define the **ideal dataset** required for monthly revenue forecasting\n",
    "2. Explore the **Online Retail.xlsx** dataset\n",
    "3. Identify **data gaps** and their impact on forecasting quality\n",
    "4. Map available data to forecasting requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeec11",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Ideal Dataset Definition\n",
    "\n",
    "### 1.1 Historical Monthly Revenue (CRITICAL)\n",
    "\n",
    "| Attribute | Specification |\n",
    "|-----------|---------------|\n",
    "| **Description** | Aggregated monthly revenue figures |\n",
    "| **Granularity** | Monthly totals |\n",
    "| **Time Span** | Minimum 24-36 months for seasonality detection |\n",
    "| **Why Needed** | Target variable; captures trends, seasonality, autoregressive patterns |\n",
    "| **Temporal Relevance** | Must be complete up to April (current month) |\n",
    "\n",
    "**Impact if Missing:** Cannot train any forecasting model. FATAL.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Daily/Weekly Sales Aggregated Monthly\n",
    "\n",
    "| Attribute | Specification |\n",
    "|-----------|---------------|\n",
    "| **Description** | Transaction-level or daily sales data |\n",
    "| **Granularity** | Daily transactions ‚Üí aggregated to monthly |\n",
    "| **Why Needed** | Enables within-month pattern analysis, volatility measurement |\n",
    "| **Temporal Relevance** | Lag features from t-1, t-2, t-3 months |\n",
    "\n",
    "**Impact if Missing:** Lose intra-month dynamics; forecast stability may suffer.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Marketing Spend by Channel\n",
    "\n",
    "| Attribute | Specification |\n",
    "|-----------|---------------|\n",
    "| **Description** | Monthly marketing expenditure by channel |\n",
    "| **Channels** | Digital, TV, Print, Email, Social |\n",
    "| **Why Needed** | Marketing drives revenue with lag effect (H3 hypothesis) |\n",
    "| **Temporal Relevance** | 1-2 month lag before revenue impact |\n",
    "\n",
    "**Impact if Missing:** Cannot model marketing ROI or lead effects.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 Promotions / Discounts\n",
    "\n",
    "| Attribute | Specification |\n",
    "|-----------|---------------|\n",
    "| **Description** | Promotional events, discount periods, campaigns |\n",
    "| **Granularity** | Event dates and discount percentages |\n",
    "| **Why Needed** | Promotions create revenue spikes; must account for or model |\n",
    "| **Temporal Relevance** | Concurrent month effect |\n",
    "\n",
    "**Impact if Missing:** Unexplained variance in revenue; reduced accuracy during promotional periods.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Customer Counts / Transactions\n",
    "\n",
    "| Attribute | Specification |\n",
    "|-----------|---------------|\n",
    "| **Description** | Unique customers, transaction counts, repeat rates |\n",
    "| **Granularity** | Monthly aggregates |\n",
    "| **Why Needed** | Revenue = Customers √ó Avg. Transaction Value; decomposition |\n",
    "| **Temporal Relevance** | Leading indicator for revenue |\n",
    "\n",
    "**Impact if Missing:** Cannot decompose revenue drivers; limited interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.6 External Signals (Optional but Valuable)\n",
    "\n",
    "| Signal | Description | Why Needed |\n",
    "|--------|-------------|------------|\n",
    "| **Holidays** | National/regional holidays | Explains demand spikes/dips |\n",
    "| **Business Days** | Working days per month | Normalizes revenue per day |\n",
    "| **Seasonality Indicators** | Quarter, fiscal period | Captures business cycles |\n",
    "| **Economic Indicators** | CPI, consumer confidence | External demand drivers |\n",
    "\n",
    "**Impact if Missing:** Model relies solely on internal data; may miss macro trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c845dde",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Load and Explore Online Retail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cd6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Online Retail Dataset\n",
    "DATA_PATH = '../data/raw/Online Retail.xlsx'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190dcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows and basic info\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Schema and Data Types\n",
    "print(\"=\" * 60)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0eb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4690d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': df.isnull().sum().values,\n",
    "    'Missing %': (df.isnull().sum().values / len(df) * 100).round(2),\n",
    "    'Non-Null Count': df.notnull().sum().values,\n",
    "    'Data Type': df.dtypes.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df.sort_values('Missing %', ascending=False)\n",
    "display(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fec0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Data\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = ['#e74c3c' if x > 0 else '#27ae60' for x in missing_df['Missing %']]\n",
    "bars = ax.barh(missing_df['Column'], missing_df['Missing %'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Missing Percentage (%)', fontsize=12)\n",
    "ax.set_title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=5, color='orange', linestyle='--', label='5% threshold')\n",
    "\n",
    "for bar, pct in zip(bars, missing_df['Missing %']):\n",
    "    ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "            f'{pct:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d9c2f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839fa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and analyze date column\n",
    "# Identify the date column (common names: InvoiceDate, Date, OrderDate)\n",
    "date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "print(f\"Detected date columns: {date_columns}\")\n",
    "\n",
    "if date_columns:\n",
    "    date_col = date_columns[0]\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"TEMPORAL COVERAGE ANALYSIS\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Date Column: {date_col}\")\n",
    "    print(f\"Date Range: {df[date_col].min()} to {df[date_col].max()}\")\n",
    "    print(f\"Total Duration: {(df[date_col].max() - df[date_col].min()).days} days\")\n",
    "    print(f\"Approximate Months: {(df[date_col].max() - df[date_col].min()).days // 30} months\")\n",
    "else:\n",
    "    print(\"No date column found! Check column names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3db3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal features\n",
    "if date_columns:\n",
    "    date_col = date_columns[0]\n",
    "    \n",
    "    df['Year'] = df[date_col].dt.year\n",
    "    df['Month'] = df[date_col].dt.month\n",
    "    df['YearMonth'] = df[date_col].dt.to_period('M')\n",
    "    df['DayOfWeek'] = df[date_col].dt.dayofweek\n",
    "    df['DayOfMonth'] = df[date_col].dt.day\n",
    "    df['WeekOfYear'] = df[date_col].dt.isocalendar().week\n",
    "    \n",
    "    print(\"Temporal features extracted:\")\n",
    "    print(df[['Year', 'Month', 'YearMonth', 'DayOfWeek', 'DayOfMonth', 'WeekOfYear']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8370a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly transaction distribution\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSACTIONS BY YEAR-MONTH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "monthly_counts = df.groupby('YearMonth').size()\n",
    "print(monthly_counts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "monthly_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('Year-Month', fontsize=12)\n",
    "ax.set_ylabel('Transaction Count', fontsize=12)\n",
    "ax.set_title('Transaction Volume by Month', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b981c4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Revenue Calculation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c596692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify revenue-related columns\n",
    "print(\"=\" * 60)\n",
    "print(\"REVENUE COLUMN IDENTIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Common patterns for revenue columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns: {numeric_cols}\")\n",
    "\n",
    "# Look for price and quantity columns\n",
    "price_cols = [col for col in df.columns if any(x in col.lower() for x in ['price', 'amount', 'value'])]\n",
    "qty_cols = [col for col in df.columns if any(x in col.lower() for x in ['quantity', 'qty', 'units'])]\n",
    "\n",
    "print(f\"\\nPrice-related columns: {price_cols}\")\n",
    "print(f\"Quantity-related columns: {qty_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Revenue (Quantity √ó UnitPrice) - Standard for Online Retail dataset\n",
    "# Adjust column names based on actual dataset\n",
    "\n",
    "# Try common column name patterns\n",
    "qty_col = None\n",
    "price_col = None\n",
    "\n",
    "for col in df.columns:\n",
    "    if 'quantity' in col.lower():\n",
    "        qty_col = col\n",
    "    if 'price' in col.lower() and 'unit' in col.lower():\n",
    "        price_col = col\n",
    "    elif 'price' in col.lower():\n",
    "        price_col = col\n",
    "\n",
    "print(f\"Quantity column: {qty_col}\")\n",
    "print(f\"Price column: {price_col}\")\n",
    "\n",
    "if qty_col and price_col:\n",
    "    df['Revenue'] = df[qty_col] * df[price_col]\n",
    "    print(f\"\\nRevenue column created: Quantity √ó UnitPrice\")\n",
    "    print(f\"Revenue Statistics:\")\n",
    "    print(df['Revenue'].describe())\n",
    "else:\n",
    "    print(\"Could not identify quantity/price columns. Manual mapping required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f02d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality: Check for negative quantities and prices (returns/cancellations)\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY: NEGATIVE VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if qty_col:\n",
    "    neg_qty = (df[qty_col] < 0).sum()\n",
    "    print(f\"Negative quantities (returns): {neg_qty:,} ({neg_qty/len(df)*100:.2f}%)\")\n",
    "\n",
    "if price_col:\n",
    "    neg_price = (df[price_col] <= 0).sum()\n",
    "    print(f\"Zero/Negative prices: {neg_price:,} ({neg_price/len(df)*100:.2f}%)\")\n",
    "\n",
    "if 'Revenue' in df.columns:\n",
    "    neg_rev = (df['Revenue'] < 0).sum()\n",
    "    zero_rev = (df['Revenue'] == 0).sum()\n",
    "    print(f\"Negative revenue: {neg_rev:,} ({neg_rev/len(df)*100:.2f}%)\")\n",
    "    print(f\"Zero revenue: {zero_rev:,} ({zero_rev/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for valid transactions (positive revenue for forecasting)\n",
    "print(\"=\" * 60)\n",
    "print(\"FILTERING VALID TRANSACTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'Revenue' in df.columns:\n",
    "    df_valid = df[df['Revenue'] > 0].copy()\n",
    "    print(f\"Original records: {len(df):,}\")\n",
    "    print(f\"Valid transactions (Revenue > 0): {len(df_valid):,}\")\n",
    "    print(f\"Removed: {len(df) - len(df_valid):,} ({(len(df) - len(df_valid))/len(df)*100:.2f}%)\")\n",
    "else:\n",
    "    df_valid = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241025cb",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Monthly Revenue Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e043af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate revenue by month - THIS IS OUR TARGET VARIABLE\n",
    "print(\"=\" * 60)\n",
    "print(\"MONTHLY REVENUE AGGREGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'Revenue' in df_valid.columns and 'YearMonth' in df_valid.columns:\n",
    "    monthly_revenue = df_valid.groupby('YearMonth').agg({\n",
    "        'Revenue': 'sum',\n",
    "        qty_col: 'sum' if qty_col else 'count',\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Add transaction count\n",
    "    monthly_txn_count = df_valid.groupby('YearMonth').size().reset_index(name='TransactionCount')\n",
    "    monthly_revenue = monthly_revenue.merge(monthly_txn_count, on='YearMonth')\n",
    "    \n",
    "    # Add unique customer count if CustomerID exists\n",
    "    customer_cols = [col for col in df_valid.columns if 'customer' in col.lower()]\n",
    "    if customer_cols:\n",
    "        customer_col = customer_cols[0]\n",
    "        monthly_customers = df_valid.groupby('YearMonth')[customer_col].nunique().reset_index(name='UniqueCustomers')\n",
    "        monthly_revenue = monthly_revenue.merge(monthly_customers, on='YearMonth')\n",
    "    \n",
    "    monthly_revenue['YearMonth'] = monthly_revenue['YearMonth'].astype(str)\n",
    "    \n",
    "    print(\"\\nMonthly Revenue Summary:\")\n",
    "    display(monthly_revenue)\n",
    "else:\n",
    "    print(\"Cannot aggregate - Revenue or YearMonth column missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Monthly Revenue Trend\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Monthly Revenue\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(monthly_revenue['YearMonth'], monthly_revenue['Revenue'], \n",
    "         marker='o', linewidth=2, markersize=8, color='#2ecc71')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Revenue')\n",
    "ax1.set_title('Monthly Revenue Trend', fontweight='bold', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Transaction Count\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(monthly_revenue['YearMonth'], monthly_revenue['TransactionCount'], \n",
    "        color='#3498db', edgecolor='black')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Transaction Count')\n",
    "ax2.set_title('Monthly Transaction Volume', fontweight='bold', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Unique Customers (if available)\n",
    "ax3 = axes[1, 0]\n",
    "if 'UniqueCustomers' in monthly_revenue.columns:\n",
    "    ax3.plot(monthly_revenue['YearMonth'], monthly_revenue['UniqueCustomers'], \n",
    "             marker='s', linewidth=2, markersize=8, color='#9b59b6')\n",
    "    ax3.set_ylabel('Unique Customers')\n",
    "    ax3.set_title('Monthly Unique Customers', fontweight='bold', fontsize=12)\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'Customer data not available', ha='center', va='center')\n",
    "ax3.set_xlabel('Month')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Average Revenue per Transaction\n",
    "ax4 = axes[1, 1]\n",
    "monthly_revenue['AvgRevPerTxn'] = monthly_revenue['Revenue'] / monthly_revenue['TransactionCount']\n",
    "ax4.bar(monthly_revenue['YearMonth'], monthly_revenue['AvgRevPerTxn'], \n",
    "        color='#e74c3c', edgecolor='black')\n",
    "ax4.set_xlabel('Month')\n",
    "ax4.set_ylabel('Avg Revenue / Transaction')\n",
    "ax4.set_title('Average Transaction Value by Month', fontweight='bold', fontsize=12)\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b4e17",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Data Gap Analysis - Available vs. Ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare available data against ideal requirements\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA GAP ANALYSIS: AVAILABLE vs. IDEAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data_requirements = {\n",
    "    'Historical Monthly Revenue': {\n",
    "        'Required': True,\n",
    "        'Available': 'Revenue' in df.columns,\n",
    "        'Source': 'Calculated from Quantity √ó UnitPrice',\n",
    "        'Impact if Missing': 'FATAL - Cannot train any model'\n",
    "    },\n",
    "    'Transaction-level Data': {\n",
    "        'Required': True,\n",
    "        'Available': True,\n",
    "        'Source': 'Each row is a transaction line item',\n",
    "        'Impact if Missing': 'Lose intra-month patterns'\n",
    "    },\n",
    "    'Customer Information': {\n",
    "        'Required': True,\n",
    "        'Available': any('customer' in col.lower() for col in df.columns),\n",
    "        'Source': 'CustomerID column',\n",
    "        'Impact if Missing': 'Cannot analyze customer behavior'\n",
    "    },\n",
    "    'Product Information': {\n",
    "        'Required': False,\n",
    "        'Available': any('stock' in col.lower() or 'product' in col.lower() or 'description' in col.lower() for col in df.columns),\n",
    "        'Source': 'StockCode/Description columns',\n",
    "        'Impact if Missing': 'Cannot do product-level analysis'\n",
    "    },\n",
    "    'Geographic Data': {\n",
    "        'Required': False,\n",
    "        'Available': any('country' in col.lower() for col in df.columns),\n",
    "        'Source': 'Country column',\n",
    "        'Impact if Missing': 'Cannot analyze regional trends'\n",
    "    },\n",
    "    'Marketing Spend': {\n",
    "        'Required': True,\n",
    "        'Available': False,\n",
    "        'Source': 'NOT IN DATASET',\n",
    "        'Impact if Missing': 'Cannot test H3 (marketing lead effect)'\n",
    "    },\n",
    "    'Promotions/Discounts': {\n",
    "        'Required': True,\n",
    "        'Available': False,\n",
    "        'Source': 'NOT IN DATASET',\n",
    "        'Impact if Missing': 'Cannot explain promotional spikes'\n",
    "    },\n",
    "    'External Economic Indicators': {\n",
    "        'Required': False,\n",
    "        'Available': False,\n",
    "        'Source': 'NOT IN DATASET (can be added externally)',\n",
    "        'Impact if Missing': 'Limited macro-economic context'\n",
    "    },\n",
    "    'Holiday Calendar': {\n",
    "        'Required': False,\n",
    "        'Available': False,\n",
    "        'Source': 'NOT IN DATASET (can be engineered)',\n",
    "        'Impact if Missing': 'May miss holiday effects'\n",
    "    }\n",
    "}\n",
    "\n",
    "gap_df = pd.DataFrame(data_requirements).T\n",
    "gap_df.index.name = 'Data Requirement'\n",
    "\n",
    "# Color coding\n",
    "def highlight_availability(val):\n",
    "    if val == True:\n",
    "        return 'background-color: #27ae60; color: white'\n",
    "    elif val == False:\n",
    "        return 'background-color: #e74c3c; color: white'\n",
    "    return ''\n",
    "\n",
    "display(gap_df.style.applymap(highlight_availability, subset=['Available', 'Required']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for Forecasting Readiness\n",
    "print(\"=\" * 80)\n",
    "print(\"FORECASTING READINESS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "available_count = sum(1 for v in data_requirements.values() if v['Available'])\n",
    "total_count = len(data_requirements)\n",
    "required_available = sum(1 for v in data_requirements.values() if v['Required'] and v['Available'])\n",
    "required_total = sum(1 for v in data_requirements.values() if v['Required'])\n",
    "\n",
    "print(f\"\\nüìä Data Availability: {available_count}/{total_count} ({available_count/total_count*100:.0f}%)\")\n",
    "print(f\"üéØ Required Data Available: {required_available}/{required_total} ({required_available/required_total*100:.0f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HYPOTHESIS TESTABILITY ASSESSMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "hypotheses = {\n",
    "    'H1: Autoregressive Revenue': {'Testable': True, 'Reason': 'Have historical revenue data'},\n",
    "    'H2: Seasonality Patterns': {'Testable': True, 'Reason': 'Have date/time information'},\n",
    "    'H3: Marketing Lead Effect': {'Testable': False, 'Reason': 'No marketing spend data'},\n",
    "    'H4: Economic Indicators': {'Testable': False, 'Reason': 'No external economic data'},\n",
    "    'H5: Business Day Effect': {'Testable': True, 'Reason': 'Can calculate from dates'},\n",
    "}\n",
    "\n",
    "for h, info in hypotheses.items():\n",
    "    status = '‚úÖ' if info['Testable'] else '‚ùå'\n",
    "    print(f\"{status} {h}: {info['Reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd2c01",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ff945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive data profile\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã DATASET PROFILE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "profile = {\n",
    "    'Total Records': f\"{len(df):,}\",\n",
    "    'Valid Transactions': f\"{len(df_valid):,}\" if 'df_valid' in dir() else 'N/A',\n",
    "    'Columns': len(df.columns),\n",
    "    'Date Range': f\"{df[date_col].min().date()} to {df[date_col].max().date()}\" if date_columns else 'N/A',\n",
    "    'Months Covered': len(monthly_revenue) if 'monthly_revenue' in dir() else 'N/A',\n",
    "    'Total Revenue': f\"${monthly_revenue['Revenue'].sum():,.2f}\" if 'monthly_revenue' in dir() else 'N/A',\n",
    "    'Avg Monthly Revenue': f\"${monthly_revenue['Revenue'].mean():,.2f}\" if 'monthly_revenue' in dir() else 'N/A',\n",
    "    'Unique Customers': f\"{df_valid[customer_col].nunique():,}\" if 'customer_col' in dir() and customer_col else 'N/A',\n",
    "}\n",
    "\n",
    "for key, value in profile.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üö¶ FORECASTING FEASIBILITY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "‚úÖ STRENGTHS:\n",
    "   ‚Ä¢ Transaction-level granularity enables rich feature engineering\n",
    "   ‚Ä¢ Customer ID allows customer behavior analysis\n",
    "   ‚Ä¢ Product/Stock data supports category-level forecasting\n",
    "   ‚Ä¢ Geographic data enables regional trend analysis\n",
    "\n",
    "‚ö†Ô∏è LIMITATIONS:\n",
    "   ‚Ä¢ No marketing spend data - cannot test marketing ROI hypothesis\n",
    "   ‚Ä¢ No promotional calendar - promotional effects unexplained\n",
    "   ‚Ä¢ No external economic indicators - limited macro context\n",
    "   ‚Ä¢ Time span may be limited - check if 24+ months available\n",
    "\n",
    "üéØ RECOMMENDED APPROACH:\n",
    "   1. Focus on autoregressive and seasonal models (H1, H2)\n",
    "   2. Engineer business day features (H5)\n",
    "   3. Create customer/product-based features\n",
    "   4. Consider external data augmentation if needed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed monthly data for modeling\n",
    "if 'monthly_revenue' in dir():\n",
    "    output_path = '../data/processed/monthly_revenue.csv'\n",
    "    monthly_revenue.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Monthly revenue data saved to: {output_path}\")\n",
    "    print(f\"   Records: {len(monthly_revenue)} months\")\n",
    "    print(f\"   Columns: {list(monthly_revenue.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0718405",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Data Preprocessing** ‚Üí Clean and transform data for modeling\n",
    "2. **Feature Engineering** ‚Üí Create lag features, seasonal indicators, business day counts\n",
    "3. **Hypothesis Testing** ‚Üí Validate H1, H2, H5 using statistical tests\n",
    "4. **Model Development** ‚Üí Build baseline and ML forecasting models\n",
    "5. **Evaluation** ‚Üí Assess forecast accuracy and stability\n",
    "\n",
    "---\n",
    "*Notebook created for Monthly Revenue Forecasting Project*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
